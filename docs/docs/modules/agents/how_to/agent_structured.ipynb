{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb69907a",
   "metadata": {},
   "source": [
    "# Returning Structured Output\n",
    "\n",
    "This notebook covers how to have an agent return a structured output.\n",
    "By default, most of the agents return a single string.\n",
    "It can often be useful to have an agent return something with more structure.\n",
    "\n",
    "\n",
    "A good example of this is an agent tasked with doing question-answering over some sources.\n",
    "Let's say we want the agent to respond not only with the answer, but also a list of the sources used.\n",
    "We then want our output to roughly follow the schema below:\n",
    "\n",
    "```python\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Final response to the question being asked\"\"\"\n",
    "    answer: str = Field(description = \"The final answer to respond to the user\")\n",
    "    sources: List[int] = Field(description=\"List of page chunks that contain answer to the question. Only include a page chunk if it contains relevant information\")\n",
    "```\n",
    "\n",
    "In this notebook we will go over an agent that has a retriever tool and responds in the correct format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc33ba5",
   "metadata": {},
   "source": [
    "## Create the Retriever\n",
    "\n",
    "In this section we will do some setup work to create our retriever over some mock data containing the \"State of the Union\" address. Importantly, we will add a \"page_chunk\" tag to the metadata of each document. This is just some fake data intended to simulate a source field. In practice, this would more likely be the URL or path of a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b62a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU chromadb langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea20467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3002ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in document to retrieve over\n",
    "loader = TextLoader(\"../../state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split document into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Here is where we add in the fake source information\n",
    "for i, doc in enumerate(texts):\n",
    "    doc.metadata[\"page_chunk\"] = i\n",
    "\n",
    "# Create our retriever\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(texts, embeddings, collection_name=\"state-of-union\")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1c106",
   "metadata": {},
   "source": [
    "## Create the tools\n",
    "\n",
    "We will now create the tools we want to give to the agent. In this case, it is just one - a tool that wraps our retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204ef7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"state-of-union-retriever\",\n",
    "    \"Query a retriever to get information about state of the union address\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af5b61b",
   "metadata": {},
   "source": [
    "## Create response schema\n",
    "\n",
    "Here is where we will define the response schema. In this case, we want the final answer to have two fields: one for the `answer`, and then another that is a list of `sources`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df91723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Final response to the question being asked\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"The final answer to respond to the user\")\n",
    "    sources: List[int] = Field(\n",
    "        description=\"List of page chunks that contain answer to the question. Only include a page chunk if it contains relevant information\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd181df",
   "metadata": {},
   "source": [
    "## Create the custom parsing logic\n",
    "\n",
    "We now create some custom parsing logic.\n",
    "How this works is that we will pass the `Response` schema to the OpenAI LLM via their `functions` parameter.\n",
    "This is similar to how we pass tools for the agent to use.\n",
    "\n",
    "When the `Response` function is called by OpenAI, we want to use that as a signal to return to the user.\n",
    "When any other function is called by OpenAI, we treat that as a tool invocation.\n",
    "\n",
    "Therefore, our parsing logic has the following blocks:\n",
    "\n",
    "- If no function is called, assume that we should use the response to respond to the user, and therefore return `AgentFinish`\n",
    "- If the `Response` function is called, respond to the user with the inputs to that function (our structured output), and therefore return `AgentFinish`\n",
    "- If any other function is called, treat that as a tool invocation, and therefore return `AgentActionMessageLog`\n",
    "\n",
    "Note that we are using `AgentActionMessageLog` rather than `AgentAction` because it lets us attach a log of messages that we can use in the future to pass back into the agent prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb73fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.agents import AgentActionMessageLog, AgentFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b46cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(output):\n",
    "    # If no function was invoked, return to user\n",
    "    if \"function_call\" not in output.additional_kwargs:\n",
    "        return AgentFinish(return_values={\"output\": output.content}, log=output.content)\n",
    "\n",
    "    # Parse out the function call\n",
    "    function_call = output.additional_kwargs[\"function_call\"]\n",
    "    name = function_call[\"name\"]\n",
    "    inputs = json.loads(function_call[\"arguments\"])\n",
    "\n",
    "    # If the Response function was invoked, return to the user with the function inputs\n",
    "    if name == \"Response\":\n",
    "        return AgentFinish(return_values=inputs, log=str(function_call))\n",
    "    # Otherwise, return an agent action\n",
    "    else:\n",
    "        return AgentActionMessageLog(\n",
    "            tool=name, tool_input=inputs, log=\"\", message_log=[output]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7401a1",
   "metadata": {},
   "source": [
    "## Create the Agent\n",
    "\n",
    "We can now put this all together! The components of this agent are:\n",
    "\n",
    "- prompt: a simple prompt with placeholders for the user's question and then the `agent_scratchpad` (any intermediate steps)\n",
    "- tools: we can attach the tools and `Response` format to the LLM as functions\n",
    "- format scratchpad: in order to format the `agent_scratchpad` from intermediate steps, we will use the standard `format_to_openai_function_messages`. This takes intermediate steps and formats them as AIMessages and FunctionMessages.\n",
    "- output parser: we will use our custom parser above to parse the response of the LLM\n",
    "- AgentExecutor: we will use the standard AgentExecutor to run the loop of agent-tool-agent-tool..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c785f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1feaeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d27dc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bab4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_functions([retriever_tool, Response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b886416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        # Format agent scratchpad from intermediate steps\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | parse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cfd783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(tools=[retriever_tool], agent=agent, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f114fec",
   "metadata": {},
   "source": [
    "## Run the agent\n",
    "\n",
    "We can now run the agent! Notice how it responds with a dictionary with two keys: `answer` and `sources`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2667c9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[36;1m\u001b[1;3mTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "\n",
      "And for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \n",
      "\n",
      "As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
      "\n",
      "While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \n",
      "\n",
      "And soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \n",
      "\n",
      "So tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \n",
      "\n",
      "First, beat the opioid epidemic.\n",
      "\n",
      "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\n",
      "\n",
      "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
      "\n",
      "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
      "\n",
      "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
      "\n",
      "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
      "\n",
      "We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
      "\n",
      "We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\u001b[0m\u001b[32;1m\u001b[1;3m{'arguments': '{\\n\"answer\": \"President Biden nominated Ketanji Brown Jackson for the United States Supreme Court and described her as one of our nation\\'s top legal minds who will continue Justice Breyer\\'s legacy of excellence.\",\\n\"sources\": [6]\\n}', 'name': 'Response'}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': \"President Biden nominated Ketanji Brown Jackson for the United States Supreme Court and described her as one of our nation's top legal minds who will continue Justice Breyer's legacy of excellence.\",\n",
       " 'sources': [6]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"what did the president say about ketanji brown jackson\"},\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
